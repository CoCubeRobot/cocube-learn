### 1. 案例目的

学习 AI 视觉感知模块的线条检测功能，并用 CoCube 实现自动巡线功能。

<video width="320" height="240" controls>
  <source src="line.mp4" type="video/mp4">
</video>
### 2. 使用材料

![个人电脑 或 平板](PC.png =300x*)
![CoCube机器人 + AI 视觉感知模块](Sentry2.png =300x*)

[巡线地图.pdf](map.pdf)

巡线地图，可下载并用A3纸印刷

### 3. 软件平台

[MicroBlocks-CoCube](https://microblocksfun.cn/run/microblocks.html#scripts=GP%20Scripts%0Adepends%20%27CoCube%27)

或直接打开添加有 AI 视觉感知模组的编程环境：[MicroBlocks-AI Camera](https://microblocksfun.cn/run/microblocks.html#scripts=GP%20Scripts%0Adepends%20%27CoCube%20Module%27%20%27Sentry2%20AI%20camera%27)

### 4. 算法知识

#### 算法简介

![](image-2.png)

检测图像中是否有线条，如果有则会返回线条的两个端点和倾斜角度，最多可同时检测5个线段，如果为曲线，则会返回近似的直线段。

点击观看视频：[Sentry2视觉传感器-线条检测算法介绍\_哔哩哔哩\_bilibili](https://www.bilibili.com/video/BV1de4y137QU/)

#### 配置参数

![](image-1.png)

UI界面中可以设置算法性能和同时检测的线段数量

**算法性能：**

根据不同的应用需求来选择合适能算法性能，有3个选项可以设置，分别为“灵敏”、“均衡”、“准确”

灵敏模式下会对小线段更为敏感，准确模式下会忽略较小的线段，默认为均衡模式

**线段数量：**

可以设置1～5条线段

#### 返回结果

![](image-3.png)

检测到线条后会返回其两个端点和倾斜角度

**注意**：水平向右为0度，逆时针增大，垂直向上为90度，水平向左为180度，一般不会向下检测输出角度

![](image.png)

最多可同时可检测5个线段，为便于UI界面上进行区分，按结果顺序依次用“红、黄、绿、蓝、紫”五种颜色进行标记

当通过主控读取寄存器时，将会返回以下的数据：

| **结果** | **含义**      |
| ------ | ----------- |
| 1      | 线段终点x坐标（高处） |
| 2      | 线段终点y坐标（高处） |
| 3      | 线段起点x坐标（低处） |
| 4      | 线段起点y坐标（低处） |
| 5      | 线段的倾斜角度     |

#### **使用技巧**

1. 背景与线条应清晰分明，比如白底黑线，如果背景杂乱，则可能会检测出背景中的线条

2. 线条粗细应适中，不可过细，也不可太宽

3. 一般来说，巡线时，第一条线段始终为屏幕下方先发现的线段，然后是分支线段

#### **需要使用到的积木说明**

1. **Sentry2 初始化积木**

一个可选参数是 i2c 地址。默认为 96。（0x60）

在使用 Sentry2 前需要先执行初始化积木。通常会放在“当启动时”帽子积木下。

![](init.png)

2. **Sentry2 设置模式积木**

![](<setmodeline.png>)

需要设置模式为line，即线条检测模式。

3. **Sentry2 检测结果**

![](result.png)

使用这个积木前需要确定line算法模式已开启。

这块积木也是用来触发检测的积木，只有先使用这块积木，才能获得检测结果。

返回的结果为当前line算法识别到的结果数量。

结果的数量会受对应算法的参数设置影响。

4. **Sentry2 线条检测对象属性**

![](linedetect.png)

返回线条检测对象id的属性，包括线段终点x坐标（高处）、线段终点y坐标（高处）、线段起点x坐标（低处）、线段起点y坐标（低处）、线段的倾斜角度。

### 5. 开始编程

1. **连接设备：**&#x901A;过有线或者无线方式，连接 MicroBlocks IDE 与 CoCube 机器人，并将 AI 视觉感知模块拓展在 CoCube 机器人前方。

2. **载入积木库：**&#x5982;未添加 Sentry2 AI 摄像头库和 CoCube 外接模块库，可先加载CoCube的外接模块库和Sentry2 AI 摄像头库。

3. **摄像头模块初始化：**&#x9009;择启动时先启用外接模块电源，然后等4秒后摄像头模块启动成功再初始化I2C接口，然后再将摄像头的算法模式设置为line模式用于色块识别。

![](linedetectinit.png)

4. **线条检测：**&#x5FAA;环判断是否有检测到Blob色块，当检测到的色块数量为1时，输出该色块的5种属性。你可以实时观察该色块的位置、大小以及颜色标签。

![](detectresult.png)

现在考虑如何根据线条的位置和角度来让CoCube保持在巡线上，因为CoCube是履带式差速轮，当其偏离巡线时需要通过调整两个车轮的转速来进行转向校正。所以我们就需要判断什么情况下需要调整转向，如下图所示：

* 1\. 首先当直线本身位置偏左时，说明此时CoCube已经偏向于巡线的右侧，而我们最希望的是CoCube能尽快回到最近的训线的中心，所以选择bottom\_X与屏幕中心(50)作差，然后除以一个比例系数得到差速值，定义为error\_1

* 2.其次当直线角度不是90度(即前方巡线存在拐弯)时说明我们需要进行转向来跟踪巡线。因此选择直角(90)与angle作差，然后除以另一个比例系数得到差速值，定义为error\_2;

![](Screenshot.png)

最终左轮的速度等于直线速度(默认25)+error\_1+error\_2, 右轮的速度等于直线速度(默认25)-error\_1-error\_2。

（注：这里error\_1和error\_2采用了负反馈的思想，根据实际的误差调整车轮转速，进而减少误差）

代码如下（[自动巡线](https://microblocks.fun/run/microblocks.html#scripts=GP%20Script%0Adepends%20%27CoCube%27%20%27Sentry2%20AI%20camera%27%0A%0Ascript%20681%2084%20%7B%0AwhenButtonPressed%20%27A%27%0Aforever%20%7B%0A%20%20if%20%28%28Sentry2_detect_result%200%29%20%3D%3D%201%29%20%7B%0A%20%20%20%20bottom_x%20%3D%20%28%27Sentry2%20detect%20lineobj%27%201%20%27bottomX%27%29%0A%20%20%20%20angle%20%3D%20%28%27Sentry2%20detect%20lineobj%27%201%20%27angle%27%29%0A%20%20%20%20wheel_error%20%3D%20%28%28%28bottom_x%20-%2050%29%20%2F%206%29%20%2B%20%28%2890%20-%20angle%29%20%2F%206%29%29%0A%20%20%20%20%27CoCube%20set%20wheel%27%20%2825%20%2B%20wheel_error%29%20%2825%20-%20wheel_error%29%0A%20%20%20%20waitMillis%2030%0A%20%20%7D%0A%7D%0A%7D%0A%0A)）：

![](scriptImage560372.png)

* **编写自己的程序：**&#x6709;了上述的调试代码，不妨尝试下改用其他参数作为负反馈项实现更高精度的跟踪，也可以自己试试组合更多的功能！

### 6. 挑战一下

基于色块识别功能，实现跟随蓝色圆柱移动的功能。

注意，需要手动设置Sentry2摄像头的色块识别的参数，将识别色块的颜色由出厂默认红色，更改为蓝色。
